{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gradient_Boosting_Assignment (Core).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AgunsBaba/Assignment/blob/master/Gradient_Boosting_Assignment_(Core).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1a1R3UyYQMH"
      },
      "source": [
        "# Intro to Gradient Boosting\n",
        "\n",
        "![gradient boosting image](https://media.geeksforgeeks.org/wp-content/uploads/20200721214745/gradientboosting.PNG)\n",
        "\n",
        "Image thanks to [Geeks for Geeks](https://www.geeksforgeeks.org/ml-gradient-boosting/)\n",
        "\n",
        "In this assignment you will:\n",
        "1. import and prepare a dataset for modeling\n",
        "2. test and evaluate 3 different boosting models and compare the fit times of each.\n",
        "3. tune the hyperparameters of the best model to reduce overfitting and improve performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBHKlzCubQOq"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import make_column_selector, make_column_transformer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report, plot_confusion_matrix\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1guzybQJjbn6"
      },
      "source": [
        "In this assignment you will be working with census data.  Your goal is to predict whether a person will make more or less than $50k per year in income.\n",
        "\n",
        "The data is available [here](https://drive.google.com/file/d/1drlRzq-lIY7rxQnvv_3fsxfIfLsjQ4A-/view?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsllcFvrb7YC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "dd68b5b5-b4df-425f-84f8-cf7891a7d45a"
      },
      "source": [
        "df = pd.read_csv('/content/census_income - census_income.csv')\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>education</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>hours-per-week</th>\n",
              "      <th>native-country</th>\n",
              "      <th>income-class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>2174</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>38</td>\n",
              "      <td>Private</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>53</td>\n",
              "      <td>Private</td>\n",
              "      <td>11th</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>28</td>\n",
              "      <td>Private</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Wife</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>Cuba</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  age  ... native-country income-class\n",
              "0           0   39  ...  United-States        <=50K\n",
              "1           1   50  ...  United-States        <=50K\n",
              "2           2   38  ...  United-States        <=50K\n",
              "3           3   53  ...  United-States        <=50K\n",
              "4           4   28  ...           Cuba        <=50K\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6_1E6psj1J0"
      },
      "source": [
        "Prepare your dataset for modeling.\n",
        "\n",
        "Remember to: \n",
        "1. Check for missing data, bad data, and duplicates.\n",
        "2. Check your target class balance.\n",
        "3. Perform your validation split\n",
        "4. Create a preprocessing pipeline to use with your models.\n",
        "5. Fit and evaluate your models using pipelines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-Wh3RssgPAu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c41d2cb6-82d0-458a-d6bf-a0e989204e2f"
      },
      "source": [
        "print(df.isna().sum()) #check for null values"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unnamed: 0        0\n",
            "age               0\n",
            "workclass         0\n",
            "education         0\n",
            "marital-status    0\n",
            "occupation        0\n",
            "relationship      0\n",
            "race              0\n",
            "sex               0\n",
            "capital-gain      0\n",
            "capital-loss      0\n",
            "hours-per-week    0\n",
            "native-country    0\n",
            "income-class      0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.duplicated().sum()) #check for duplication"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifXHZhuKej1Z",
        "outputId": "d024180a-9202-495b-e6fd-19399d131f6e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_WGYDjxepzg",
        "outputId": "4fa09253-0278-40ed-e292-d170354094ee"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 32561 entries, 0 to 32560\n",
            "Data columns (total 14 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   Unnamed: 0      32561 non-null  int64 \n",
            " 1   age             32561 non-null  int64 \n",
            " 2   workclass       32561 non-null  object\n",
            " 3   education       32561 non-null  object\n",
            " 4   marital-status  32561 non-null  object\n",
            " 5   occupation      32561 non-null  object\n",
            " 6   relationship    32561 non-null  object\n",
            " 7   race            32561 non-null  object\n",
            " 8   sex             32561 non-null  object\n",
            " 9   capital-gain    32561 non-null  int64 \n",
            " 10  capital-loss    32561 non-null  int64 \n",
            " 11  hours-per-week  32561 non-null  int64 \n",
            " 12  native-country  32561 non-null  object\n",
            " 13  income-class    32561 non-null  object\n",
            "dtypes: int64(5), object(9)\n",
            "memory usage: 3.5+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OI6ExMIdjXWO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check income class balance\n",
        "df['income-class'].value_counts(normalize=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxOtUvQlfj2R",
        "outputId": "63fa08e6-65ed-4693-c519-3c7cc364b1ff"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<=50K    0.75919\n",
              ">50K     0.24081\n",
              "Name: income-class, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define target and feature labels\n",
        "X = df.drop(columns=['income-class', 'Unnamed: 0'])\n",
        "y = df['income-class']"
      ],
      "metadata": {
        "id": "Hm7WTZN9jNrh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Perform validation split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "ue45wrR6ikfA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pre-processing pipeline\n",
        "cat_selector = make_column_selector(dtype_include=object) #instantiate selecting categorical columns\n",
        "num_selector = make_column_selector(dtype_include=int) #instantiate selecting numerical columns\n",
        "\n",
        "oht = OneHotEncoder(sparse=False, handle_unknown='ignore') #instantiate one hot enncoder transfromer\n",
        "scaler = StandardScaler() #instantiate scaler transformer\n",
        "\n",
        "#make pipeline for the categorical columns\n",
        "cat_pipe = make_pipeline(oht)\n",
        "num_pipe = make_pipeline(scaler)\n",
        "\n",
        "\n",
        "#create pre-processing tuples\n",
        "cat_tuple = (cat_pipe, cat_selector)\n",
        "num_tuple = (num_pipe, num_selector)\n",
        "\n",
        "\n",
        "#make column transformers\n",
        "col_transformer = make_column_transformer(num_tuple, cat_tuple, remainder='passthrough')\n"
      ],
      "metadata": {
        "id": "s456f31rkrBv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0mmi7OMOqE1b"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOIAxdz7k7d_"
      },
      "source": [
        "# eXtreme Gradient Boosting\n",
        "We are going to compare both metrics and fit times for our models.  Notice the 'cell magic' in the top of the cell below.  By putting `%%time` at the top of a notebook cell, we can tell it to output how long that cell took to run.  We can use this to compare the speed of each of our different models.  Fit times can be very important for models in deployment, especially with very large dataset and/or many features.\n",
        "\n",
        "Instantiate an eXtreme Gradient Boosting Classifier (XGBClassifier) below, fit it, and print out a classification report.  Take note of the accuracy, recall, precision, and f1-score, as well as the run time of the cell to compare to our next models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "du_JvXzBgHcU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "514bbe60-e4ce-494e-c91a-0d4d732bfb28"
      },
      "source": [
        "%%time\n",
        "#instantiate the model\n",
        "xgb =  XGBClassifier(random_state=42)\n",
        "\n",
        "#create an XGB pipeline\n",
        "xgb_pipe = make_pipeline(col_transformer, xgb)\n",
        "\n",
        "#fit the model\n",
        "xgb_pipe.fit(X_train, y_train)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 5.08 s, sys: 62 ms, total: 5.14 s\n",
            "Wall time: 5.21 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMtVjYZ54RjX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f26c0df-a618-4440-bdfd-d5d2cb7f533a"
      },
      "source": [
        "#generate xgb classification report\n",
        "pred_xgb = xgb_pipe.predict(X_test)\n",
        "pred_xgb_train = xgb_pipe.predict(X_train)\n",
        "\n",
        "print(classification_report(y_test, pred_xgb))\n",
        "print(classification_report(y_train, pred_xgb_train))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       <=50K       0.88      0.95      0.91      7455\n",
            "        >50K       0.79      0.58      0.67      2314\n",
            "\n",
            "    accuracy                           0.86      9769\n",
            "   macro avg       0.84      0.76      0.79      9769\n",
            "weighted avg       0.86      0.86      0.86      9769\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       <=50K       0.88      0.96      0.91     17265\n",
            "        >50K       0.81      0.58      0.68      5527\n",
            "\n",
            "    accuracy                           0.86     22792\n",
            "   macro avg       0.84      0.77      0.80     22792\n",
            "weighted avg       0.86      0.86      0.86     22792\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DdMdPlLgrVm"
      },
      "source": [
        "Which target class is your model better at predicting?  Is it significantly overfit?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model is better at predicting the <=50K category with a higher f1-score. However, our model  I do not think our model is overfitting given there's a comparable level of accuracy on the training and test set"
      ],
      "metadata": {
        "id": "-o2_g96AwMJY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWu_4o2nm-HP"
      },
      "source": [
        "# More Gradient Boosting\n",
        "\n",
        "Now fit and evaluate a Light Gradient Boosting Machine and a the Scikit Learn (sklearn) gradient boost model.  Remember to use the `%%time` cell magic command to get the run time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpRP2a_UlTYX"
      },
      "source": [
        "## LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKxj1YCloRML",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56a142ab-84ea-4fb2-ad42-a17bb2c8c196"
      },
      "source": [
        "%%time\n",
        "#instantiate the model\n",
        "lgbm =  LGBMClassifier(random_state=42)\n",
        "\n",
        "#create an LGBM pipeline\n",
        "lgbm_pipe = make_pipeline(col_transformer, lgbm)\n",
        "\n",
        "#fit the model\n",
        "lgbm_pipe.fit(X_train, y_train)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 529 ms, sys: 0 ns, total: 529 ms\n",
            "Wall time: 540 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDkByQTB4QP_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e23380da-5712-4850-a268-cac40e02258e"
      },
      "source": [
        "#generate lgbm classification report\n",
        "pred_lgbm = lgbm_pipe.predict(X_test)\n",
        "pred_lgbm_train = lgbm_pipe.predict(X_train)\n",
        "\n",
        "print(classification_report(y_test, pred_lgbm))\n",
        "print(classification_report(y_train, pred_lgbm_train))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       <=50K       0.90      0.94      0.92      7455\n",
            "        >50K       0.77      0.66      0.71      2314\n",
            "\n",
            "    accuracy                           0.87      9769\n",
            "   macro avg       0.83      0.80      0.81      9769\n",
            "weighted avg       0.87      0.87      0.87      9769\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       <=50K       0.91      0.95      0.93     17265\n",
            "        >50K       0.82      0.69      0.75      5527\n",
            "\n",
            "    accuracy                           0.89     22792\n",
            "   macro avg       0.86      0.82      0.84     22792\n",
            "weighted avg       0.88      0.89      0.88     22792\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iT6rGsjlWfC"
      },
      "source": [
        "## GradientBoostingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_zcJ2pVoSUr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d5cb65f-b39c-4a51-8a19-b46f7304ae22"
      },
      "source": [
        "%%time\n",
        "#instantiate the model\n",
        "gbc =  GradientBoostingClassifier(random_state=42)\n",
        "\n",
        "#create a GBC pipeline\n",
        "gbc_pipe = make_pipeline(col_transformer, gbc)\n",
        "\n",
        "#fit the model\n",
        "gbc_pipe.fit(X_train, y_train)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 5.68 s, sys: 0 ns, total: 5.68 s\n",
            "Wall time: 5.68 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSvJ4frz4Q0P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0750599a-2082-4ece-9df9-7e4bf55d5fde"
      },
      "source": [
        "#generate gbc classification report\n",
        "pred_gbc = gbc_pipe.predict(X_test)\n",
        "pred_gbc_train = gbc_pipe.predict(X_train)\n",
        "\n",
        "print(classification_report(y_test, pred_gbc))\n",
        "print(classification_report(y_train, pred_gbc_train))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       <=50K       0.88      0.95      0.92      7455\n",
            "        >50K       0.79      0.59      0.68      2314\n",
            "\n",
            "    accuracy                           0.87      9769\n",
            "   macro avg       0.84      0.77      0.80      9769\n",
            "weighted avg       0.86      0.87      0.86      9769\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       <=50K       0.88      0.96      0.92     17265\n",
            "        >50K       0.81      0.60      0.69      5527\n",
            "\n",
            "    accuracy                           0.87     22792\n",
            "   macro avg       0.85      0.78      0.80     22792\n",
            "weighted avg       0.86      0.87      0.86     22792\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9VNanqkoTf7"
      },
      "source": [
        "\n",
        "# Tuning Gradient Boosting Models\n",
        "\n",
        "Tree-based gradient boosting models have a LOT of hyperparameters to tune.  Here are the documentation pages for each of the 3 models you used today:\n",
        "\n",
        "1. [XGBoost Hyperparameter Documentation](https://xgboost.readthedocs.io/en/latest/parameter.html)\n",
        "2. [LightGBM Hyperparameter Documentation](https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html)\n",
        "3. [Scikit-learn Gradient Boosting Classifier Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)\n",
        "\n",
        "Choose the model you felt performed the best when comparing multiple metrics and the runtime for fitting, and use GridSearchCV to try at least 2 different values each for 3 different hyper parameters in boosting model you chose.\n",
        "\n",
        "See if you can create a model with an accuracy between 86 and 90.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I really like the performance of the LGBM model. It took about 540ms to fit (significantly faster than the other models) and had the highest accuracy score"
      ],
      "metadata": {
        "id": "pBkspLAM0cdZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#get parameters for the LGBM model\n",
        "lgbm_pipe.get_params()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuLIIfUP0yp5",
        "outputId": "6a5d80a3-4bdf-4905-b958-1379a5501152"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'columntransformer': ColumnTransformer(remainder='passthrough',\n",
              "                   transformers=[('pipeline-1',\n",
              "                                  Pipeline(steps=[('standardscaler',\n",
              "                                                   StandardScaler())]),\n",
              "                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f6651894fd0>),\n",
              "                                 ('pipeline-2',\n",
              "                                  Pipeline(steps=[('onehotencoder',\n",
              "                                                   OneHotEncoder(handle_unknown='ignore',\n",
              "                                                                 sparse=False))]),\n",
              "                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f6651894ad0>)]),\n",
              " 'columntransformer__n_jobs': None,\n",
              " 'columntransformer__pipeline-1': Pipeline(steps=[('standardscaler', StandardScaler())]),\n",
              " 'columntransformer__pipeline-1__memory': None,\n",
              " 'columntransformer__pipeline-1__standardscaler': StandardScaler(),\n",
              " 'columntransformer__pipeline-1__standardscaler__copy': True,\n",
              " 'columntransformer__pipeline-1__standardscaler__with_mean': True,\n",
              " 'columntransformer__pipeline-1__standardscaler__with_std': True,\n",
              " 'columntransformer__pipeline-1__steps': [('standardscaler',\n",
              "   StandardScaler())],\n",
              " 'columntransformer__pipeline-1__verbose': False,\n",
              " 'columntransformer__pipeline-2': Pipeline(steps=[('onehotencoder',\n",
              "                  OneHotEncoder(handle_unknown='ignore', sparse=False))]),\n",
              " 'columntransformer__pipeline-2__memory': None,\n",
              " 'columntransformer__pipeline-2__onehotencoder': OneHotEncoder(handle_unknown='ignore', sparse=False),\n",
              " 'columntransformer__pipeline-2__onehotencoder__categories': 'auto',\n",
              " 'columntransformer__pipeline-2__onehotencoder__drop': None,\n",
              " 'columntransformer__pipeline-2__onehotencoder__dtype': numpy.float64,\n",
              " 'columntransformer__pipeline-2__onehotencoder__handle_unknown': 'ignore',\n",
              " 'columntransformer__pipeline-2__onehotencoder__sparse': False,\n",
              " 'columntransformer__pipeline-2__steps': [('onehotencoder',\n",
              "   OneHotEncoder(handle_unknown='ignore', sparse=False))],\n",
              " 'columntransformer__pipeline-2__verbose': False,\n",
              " 'columntransformer__remainder': 'passthrough',\n",
              " 'columntransformer__sparse_threshold': 0.3,\n",
              " 'columntransformer__transformer_weights': None,\n",
              " 'columntransformer__transformers': [('pipeline-1',\n",
              "   Pipeline(steps=[('standardscaler', StandardScaler())]),\n",
              "   <sklearn.compose._column_transformer.make_column_selector at 0x7f6651894fd0>),\n",
              "  ('pipeline-2', Pipeline(steps=[('onehotencoder',\n",
              "                    OneHotEncoder(handle_unknown='ignore', sparse=False))]), <sklearn.compose._column_transformer.make_column_selector at 0x7f6651894ad0>)],\n",
              " 'columntransformer__verbose': False,\n",
              " 'columntransformer__verbose_feature_names_out': True,\n",
              " 'lgbmclassifier': LGBMClassifier(random_state=42),\n",
              " 'lgbmclassifier__boosting_type': 'gbdt',\n",
              " 'lgbmclassifier__class_weight': None,\n",
              " 'lgbmclassifier__colsample_bytree': 1.0,\n",
              " 'lgbmclassifier__importance_type': 'split',\n",
              " 'lgbmclassifier__learning_rate': 0.1,\n",
              " 'lgbmclassifier__max_depth': -1,\n",
              " 'lgbmclassifier__min_child_samples': 20,\n",
              " 'lgbmclassifier__min_child_weight': 0.001,\n",
              " 'lgbmclassifier__min_split_gain': 0.0,\n",
              " 'lgbmclassifier__n_estimators': 100,\n",
              " 'lgbmclassifier__n_jobs': -1,\n",
              " 'lgbmclassifier__num_leaves': 31,\n",
              " 'lgbmclassifier__objective': None,\n",
              " 'lgbmclassifier__random_state': 42,\n",
              " 'lgbmclassifier__reg_alpha': 0.0,\n",
              " 'lgbmclassifier__reg_lambda': 0.0,\n",
              " 'lgbmclassifier__silent': True,\n",
              " 'lgbmclassifier__subsample': 1.0,\n",
              " 'lgbmclassifier__subsample_for_bin': 200000,\n",
              " 'lgbmclassifier__subsample_freq': 0,\n",
              " 'memory': None,\n",
              " 'steps': [('columntransformer', ColumnTransformer(remainder='passthrough',\n",
              "                     transformers=[('pipeline-1',\n",
              "                                    Pipeline(steps=[('standardscaler',\n",
              "                                                     StandardScaler())]),\n",
              "                                    <sklearn.compose._column_transformer.make_column_selector object at 0x7f6651894fd0>),\n",
              "                                   ('pipeline-2',\n",
              "                                    Pipeline(steps=[('onehotencoder',\n",
              "                                                     OneHotEncoder(handle_unknown='ignore',\n",
              "                                                                   sparse=False))]),\n",
              "                                    <sklearn.compose._column_transformer.make_column_selector object at 0x7f6651894ad0>)])),\n",
              "  ('lgbmclassifier', LGBMClassifier(random_state=42))],\n",
              " 'verbose': False}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {'lgbmclassifier__num_leaves': [30, 60, 100],\n",
        "              'lgbmclassifier__min_child_samples': [10, 20, 30],\n",
        "              'lgbmclassifier__n_estimators': [150, 450, 600]}\n",
        "\n",
        "grid = GridSearchCV(lgbm_pipe, param_grid)"
      ],
      "metadata": {
        "id": "Bvep8XC-6WHD"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3M-SZpN_7iN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d336183-e89b-4327-e1ec-0ca7c10e0506"
      },
      "source": [
        "%%time\n",
        "grid.fit(X_train, y_train)\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3min 59s, sys: 6.46 s, total: 4min 6s\n",
            "Wall time: 4min 5s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(estimator=Pipeline(steps=[('columntransformer',\n",
              "                                        ColumnTransformer(remainder='passthrough',\n",
              "                                                          transformers=[('pipeline-1',\n",
              "                                                                         Pipeline(steps=[('standardscaler',\n",
              "                                                                                          StandardScaler())]),\n",
              "                                                                         <sklearn.compose._column_transformer.make_column_selector object at 0x7f6651894fd0>),\n",
              "                                                                        ('pipeline-2',\n",
              "                                                                         Pipeline(steps=[('onehotencoder',\n",
              "                                                                                          OneHotEncoder(handle_unknown='ignore',\n",
              "                                                                                                        sparse=False))]),\n",
              "                                                                         <sklearn.compose._column_transformer.make_column_selector object at 0x7f6651894ad0>)])),\n",
              "                                       ('lgbmclassifier',\n",
              "                                        LGBMClassifier(random_state=42))]),\n",
              "             param_grid={'lgbmclassifier__min_child_samples': [10, 20, 30],\n",
              "                         'lgbmclassifier__n_estimators': [150, 450, 600],\n",
              "                         'lgbmclassifier__num_leaves': [30, 60, 100]})"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(grid.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhbZ8zhKFxyT",
        "outputId": "3056c1f6-73d1-45a5-a232-02715a7261dc"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'lgbmclassifier__min_child_samples': 10, 'lgbmclassifier__n_estimators': 150, 'lgbmclassifier__num_leaves': 30}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#instantiate lgbm with the bestparams\n",
        "lgbm_best =  LGBMClassifier(min_child_samples=10, n_estimators=150, num_leaves=30, random_state=42)\n",
        "\n",
        "#create an LGBM pipeline\n",
        "lgbm_pipe_best = make_pipeline(col_transformer, lgbm_best)\n",
        "\n",
        "#fit the model\n",
        "lgbm_pipe_best.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUL1pdxNF62P",
        "outputId": "7b56ac2d-07c5-417a-db69-57793dd39f65"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('columntransformer',\n",
              "                 ColumnTransformer(remainder='passthrough',\n",
              "                                   transformers=[('pipeline-1',\n",
              "                                                  Pipeline(steps=[('standardscaler',\n",
              "                                                                   StandardScaler())]),\n",
              "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f6651894fd0>),\n",
              "                                                 ('pipeline-2',\n",
              "                                                  Pipeline(steps=[('onehotencoder',\n",
              "                                                                   OneHotEncoder(handle_unknown='ignore',\n",
              "                                                                                 sparse=False))]),\n",
              "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f6651894ad0>)])),\n",
              "                ('lgbmclassifier',\n",
              "                 LGBMClassifier(min_child_samples=10, n_estimators=150,\n",
              "                                num_leaves=30, random_state=42))])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_pred = lgbm_pipe_best.predict(X_test)\n",
        "best_pred_train = lgbm_pipe_best.predict(X_train)\n",
        "\n",
        "\n",
        "print(classification_report(y_test, best_pred))\n",
        "print(classification_report(y_train, best_pred_train))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icDmexpCG5Mh",
        "outputId": "446a9af2-b722-4c12-dea1-d73e30924818"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       <=50K       0.90      0.94      0.92      7455\n",
            "        >50K       0.77      0.67      0.71      2314\n",
            "\n",
            "    accuracy                           0.87      9769\n",
            "   macro avg       0.83      0.80      0.82      9769\n",
            "weighted avg       0.87      0.87      0.87      9769\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       <=50K       0.91      0.95      0.93     17265\n",
            "        >50K       0.83      0.71      0.77      5527\n",
            "\n",
            "    accuracy                           0.89     22792\n",
            "   macro avg       0.87      0.83      0.85     22792\n",
            "weighted avg       0.89      0.89      0.89     22792\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAV4kPhjHGf5"
      },
      "source": [
        "# Evaluation\n",
        "\n",
        "Evaluate your model using a classifiation report and/or a confusion matrix.  Explain in text how your model performed in terms of precision, recall, and it's ability to predict each of the two classes.  Also talk about the benefits or drawbacks of the computation time of that model."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the classification report, the lgbm model after Grid Search did not significantly improve the performance of the model with identical precision, recall and f1-score. My hypothesis is that with more compute resources to accomodate extensive Grid Search, it's possible to find best hyperparameter values to improve the model. It also took more than 4 minutes to train the model which might not be suitable for production system. Again, optimizing an LGBM model using Grid Search in a production system would require adequate compute resources."
      ],
      "metadata": {
        "id": "dxy2vh1kNUDt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjtsxJQ5l7Hi"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "In this assignment you practiced:\n",
        "1. data cleaning\n",
        "2. instantiating, fitting, and evaluating boosting models using multiple metrics\n",
        "3. timing how long it takes a model to fit and comparing run times between multiple models\n",
        "4. and choosing a final model based on multiple metrics.\n",
        "\n"
      ]
    }
  ]
}